<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>MCBoost - Basics and Extensions</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">MCBoost - Basics and Extensions</h1>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;mcboost&quot;</span>)</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;mlr3&quot;</span>)</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">83007</span>)</span></code></pre></div>
<div id="example-0-multi-accuracy-in-6-lines-of-code" class="section level2">
<h2>Example 0: Multi-Accuracy in 6 lines of code</h2>
<p>As a brief introduction we show how to use <strong>mcboost</strong>
in only 6 lines of code. For our example, we use the data from the
<em>sonar</em> binary classification task. We instantiate a
<code>MCBoost</code> instance by specifying a
<code>auditor_fitter</code>. This <code>auditor_fitter</code> defines
the splits into groups in each boosting iteration based on the obtained
residuals. In this example, we choose a <code>Tree</code> based model.
Afterwards, we run the <code>$multicalibrate()</code> method on our data
to start multi-calibration. We only use the first 200 samples of the
<em>sonar</em> data set to train our multi-calibrated model.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>tsk <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">&quot;sonar&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>d <span class="ot">=</span> tsk<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> tsk<span class="sc">$</span>feature_names)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>l <span class="ot">=</span> tsk<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> tsk<span class="sc">$</span>target_names)[[<span class="dv">1</span>]]</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>mc <span class="ot">=</span> MCBoost<span class="sc">$</span><span class="fu">new</span>(<span class="at">auditor_fitter =</span> <span class="st">&quot;TreeAuditorFitter&quot;</span>)</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">multicalibrate</span>(d[<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>,], l[<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>])</span></code></pre></div>
<p>After the calibration, we use the model to predict on the left-out
data (8 observations).</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">predict_probs</span>(d[<span class="dv">201</span><span class="sc">:</span><span class="dv">208</span>,])</span></code></pre></div>
</div>
<div id="what-does-mcboost-do" class="section level2">
<h2>What does mcboost do?</h2>
<p>Internally mcboost runs the following procedure <code>max_iter</code>
times:</p>
<ol style="list-style-type: decimal">
<li>Predict on X using the model from the previous iteration,
<code>init_predictor</code> in the first iteration.</li>
<li>Compute the residuals <code>res = y - y_hat</code></li>
<li>Split predictions into <code>num_buckets</code> according to
<code>y_hat</code>.</li>
<li>Fit the auditor (<code>auditor_fitter</code>) (here
called<code>c(x)</code>) on the data in each bucket with target variable
<code>r</code>.</li>
<li>Compute <code>misscal = mean(c(x) * res(x))</code></li>
<li>if <code>misscal &gt; alpha</code>: For the bucket with highest
<code>misscal</code>, update the model using the prediction
<code>c(x)</code>. else: Stop the procedure</li>
</ol>
<p>A lot more details can be found either in the code, or in the
corresponding publications.</p>
</div>
<div id="example-1-multi-accuracy-boosting-on-the-adult-dataset" class="section level2">
<h2>Example 1: Multi-Accuracy Boosting on the Adult Dataset</h2>
<p>First we download the data and create an <code>mlr3</code>
classification task:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb4-2"><a href="#cb4-2" tabindex="-1"></a>adult_train <span class="ot">=</span> <span class="fu">fread</span>(</span>
<span id="cb4-3"><a href="#cb4-3" tabindex="-1"></a>  <span class="st">&quot;https://raw.githubusercontent.com/Yorko/mlcourse.ai/master/data/adult_train.csv&quot;</span>,</span>
<span id="cb4-4"><a href="#cb4-4" tabindex="-1"></a>  <span class="at">stringsAsFactors =</span> <span class="cn">TRUE</span></span>
<span id="cb4-5"><a href="#cb4-5" tabindex="-1"></a>)</span>
<span id="cb4-6"><a href="#cb4-6" tabindex="-1"></a>adult_train<span class="sc">$</span>Country <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb4-7"><a href="#cb4-7" tabindex="-1"></a>adult_train<span class="sc">$</span>fnlwgt <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb4-8"><a href="#cb4-8" tabindex="-1"></a>train_tsk <span class="ot">=</span> TaskClassif<span class="sc">$</span><span class="fu">new</span>(<span class="st">&quot;adult_train&quot;</span>, adult_train, <span class="at">target =</span> <span class="st">&quot;Target&quot;</span>)</span></code></pre></div>
<p>We removed the features <code>Country</code> and <code>fnlwgt</code>
since we expect them to have no predictive power. <code>fnlwgt</code>
means final weight and aims to allocate similar weights to people with
similar demographic characteristics, while <code>Country</code> has 42
distinct levels but 89 % of the observations are from the United
States.</p>
<div id="preprocessing" class="section level3">
<h3>1.1 Preprocessing</h3>
<p>Then we do basic preprocessing:</p>
<ul>
<li>Collapse rarest factors according to their prevalence</li>
<li>Drop missing factor levels</li>
<li>One-hot encode categorical variables</li>
<li>Impute NA’s using a histogram approach</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="fu">library</span>(mlr3pipelines)</span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a>pipe <span class="ot">=</span> <span class="fu">po</span>(<span class="st">&quot;collapsefactors&quot;</span>, <span class="at">no_collapse_above_prevalence =</span> <span class="fl">0.0006</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">&quot;fixfactors&quot;</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">&quot;encode&quot;</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a>  <span class="fu">po</span>(<span class="st">&quot;imputehist&quot;</span>)</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a>prep_task <span class="ot">=</span> pipe<span class="sc">$</span><span class="fu">train</span>(train_tsk)[[<span class="dv">1</span>]]</span></code></pre></div>
<p>In order to simulate settings where a sensitive feature is not
available, we remove the (dummy encoded) feature <code>Race</code> from
the training task.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>prep_task<span class="sc">$</span><span class="fu">set_col_roles</span>(<span class="fu">c</span>(<span class="st">&quot;Race.Amer.Indian.Eskimo&quot;</span>, <span class="st">&quot;Race.Asian.Pac.Islander&quot;</span>, <span class="st">&quot;Race.Black&quot;</span>, <span class="st">&quot;Race.Other&quot;</span>, <span class="st">&quot;Race.White&quot;</span>), <span class="at">remove_from =</span> <span class="st">&quot;feature&quot;</span>)</span></code></pre></div>
<p>Now we fit a <code>random forest</code>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a><span class="fu">library</span>(mlr3learners)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>l <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">&quot;classif.ranger&quot;</span>, <span class="at">num.trees =</span> <span class="dv">10</span><span class="dt">L</span>, <span class="at">predict_type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a>l<span class="sc">$</span><span class="fu">train</span>(prep_task)</span></code></pre></div>
</div>
<div id="mcboost" class="section level3">
<h3>1.2 MCBoost</h3>
<p>A simple way to use the predictions from any <code>model</code> in
<strong>mcboost</strong> is to wrap the predict function and provide it
as an initial predictor. This can be done from any model / any library.
Note, that we have to make sure, that our <code>init_predictor</code>
returns a numeric vector of predictions.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>init_predictor <span class="ot">=</span> <span class="cf">function</span>(data) {</span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>  l<span class="sc">$</span><span class="fu">predict_newdata</span>(data)<span class="sc">$</span>prob[, <span class="dv">2</span>]</span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>}</span></code></pre></div>
<p>As <strong>mcboost</strong> requires the data to be provided in
<code>X, y</code> format (a <code>data.table</code> or
<code>data.frame</code> of features and a vector of labels), we create
those two objects.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>data <span class="ot">=</span> prep_task<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> prep_task<span class="sc">$</span>feature_names)</span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>labels <span class="ot">=</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">one_hot</span>(prep_task<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> prep_task<span class="sc">$</span>target_names)[[<span class="dv">1</span>]])</span></code></pre></div>
<p>We use a ridge regularized linear regression model as the
auditor.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>mc <span class="ot">=</span> MCBoost<span class="sc">$</span><span class="fu">new</span>(<span class="at">auditor_fitter =</span> <span class="st">&quot;RidgeAuditorFitter&quot;</span>, <span class="at">init_predictor =</span> init_predictor)</span>
<span id="cb10-2"><a href="#cb10-2" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">multicalibrate</span>(data, labels)</span></code></pre></div>
<p>The <code>print</code> method additionally lists the average auditor
values in the different buckets in each iteration:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>mc</span></code></pre></div>
</div>
<div id="evaluation-on-test-data" class="section level3">
<h3>1.3 Evaluation on Test Data</h3>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>adult_test <span class="ot">=</span> <span class="fu">fread</span>(</span>
<span id="cb12-2"><a href="#cb12-2" tabindex="-1"></a>  <span class="st">&quot;https://raw.githubusercontent.com/Yorko/mlcourse.ai/master/data/adult_test.csv&quot;</span>,</span>
<span id="cb12-3"><a href="#cb12-3" tabindex="-1"></a>  <span class="at">stringsAsFactors =</span> <span class="cn">TRUE</span></span>
<span id="cb12-4"><a href="#cb12-4" tabindex="-1"></a>)</span>
<span id="cb12-5"><a href="#cb12-5" tabindex="-1"></a>adult_test<span class="sc">$</span>Country <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb12-6"><a href="#cb12-6" tabindex="-1"></a>adult_test<span class="sc">$</span>fnlwgt <span class="ot">=</span> <span class="cn">NULL</span></span>
<span id="cb12-7"><a href="#cb12-7" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" tabindex="-1"></a><span class="co"># The first row seems to have an error</span></span>
<span id="cb12-9"><a href="#cb12-9" tabindex="-1"></a>adult_test <span class="ot">=</span> adult_test[Target <span class="sc">!=</span> <span class="st">&quot;&quot;</span>,]</span>
<span id="cb12-10"><a href="#cb12-10" tabindex="-1"></a>adult_test<span class="sc">$</span>Target <span class="ot">=</span> <span class="fu">droplevels</span>(adult_test<span class="sc">$</span>Target)</span>
<span id="cb12-11"><a href="#cb12-11" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" tabindex="-1"></a><span class="co"># Note, that we have to convert columns from numeric to integer here:</span></span>
<span id="cb12-13"><a href="#cb12-13" tabindex="-1"></a>sdc <span class="ot">=</span> train_tsk<span class="sc">$</span>feature_types[type <span class="sc">==</span> <span class="st">&quot;integer&quot;</span>, id]</span>
<span id="cb12-14"><a href="#cb12-14" tabindex="-1"></a>adult_test[, (sdc) <span class="sc">:=</span> <span class="fu">lapply</span>(.SD, as.integer), .SDcols <span class="ot">=</span> sdc]</span>
<span id="cb12-15"><a href="#cb12-15" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" tabindex="-1"></a>test_tsk <span class="ot">=</span> TaskClassif<span class="sc">$</span><span class="fu">new</span>(<span class="st">&quot;adult_test&quot;</span>, adult_test, <span class="at">target =</span> <span class="st">&quot;Target&quot;</span>)</span>
<span id="cb12-17"><a href="#cb12-17" tabindex="-1"></a>prep_test <span class="ot">=</span> pipe<span class="sc">$</span><span class="fu">predict</span>(test_tsk)[[<span class="dv">1</span>]]</span></code></pre></div>
<p>Now, we can again extract <code>X, y</code>.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>test_data <span class="ot">=</span> prep_test<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> prep_test<span class="sc">$</span>feature_names)</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a>test_labels <span class="ot">=</span> <span class="dv">1</span> <span class="sc">-</span> <span class="fu">one_hot</span>(prep_test<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> prep_test<span class="sc">$</span>target_names)[[<span class="dv">1</span>]])</span></code></pre></div>
<p>and <strong>predict</strong>.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>prs <span class="ot">=</span> mc<span class="sc">$</span><span class="fu">predict_probs</span>(test_data)</span></code></pre></div>
<p>The accuracy of the multi-calibrated model</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">round</span>(prs) <span class="sc">==</span> test_labels)</span></code></pre></div>
<p>is similar to the non-calibrated model.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">round</span>(<span class="fu">init_predictor</span>(test_data)) <span class="sc">==</span> test_labels)</span></code></pre></div>
<p>But if we have a look at the bias for the different subpopulations of
feature <code>Race</code>, we can see that the predictions got more
calibrated. Note that we did not explicitly give neither the initial
model nor the auditor access to the feature <code>Race</code>.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="co"># Get bias per subgroup for multi-calibrated predictor</span></span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a>adult_test<span class="sc">$</span>biasmc <span class="ot">=</span> (prs <span class="sc">-</span> test_labels)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a>adult_test[, .(<span class="fu">abs</span>(<span class="fu">mean</span>(biasmc)), .N), by <span class="ot">=</span> .(Race)]</span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="co"># Get bias per subgroup for initial predictor</span></span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a>adult_test<span class="sc">$</span>biasinit <span class="ot">=</span> (<span class="fu">init_predictor</span>(test_data) <span class="sc">-</span> test_labels)</span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a>adult_test[, .(<span class="fu">abs</span>(<span class="fu">mean</span>(biasinit)), .N), by <span class="ot">=</span> .(Race)]</span></code></pre></div>
</div>
<div id="the-auditor-effect" class="section level3">
<h3>1.4 The Auditor Effect</h3>
<p>We can also obtain the auditor effect after multicalibration. This
indicates “how much” each observation has been affected by
multi-calibration (on average across iterations).</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" tabindex="-1"></a>ae <span class="ot">=</span> mc<span class="sc">$</span><span class="fu">auditor_effect</span>(test_data)</span>
<span id="cb18-2"><a href="#cb18-2" tabindex="-1"></a><span class="fu">hist</span>(ae)</span></code></pre></div>
<p>We can see that there are a few instances with more pronounced
effects, while most have actually only a low effect.</p>
<p>In order to get more insights, we compute quantiles of the less and
more effected population (median as cut-point) and analyze
differences.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" tabindex="-1"></a>effect <span class="ot">=</span> <span class="fu">apply</span>(test_data[ae <span class="sc">&gt;=</span> <span class="fu">median</span>(ae[ae <span class="sc">&gt;</span> <span class="dv">0</span>]),], <span class="dv">2</span>, quantile)</span>
<span id="cb19-2"><a href="#cb19-2" tabindex="-1"></a>no_effect  <span class="ot">=</span> <span class="fu">apply</span>(test_data[ae <span class="sc">&lt;</span> <span class="fu">median</span>(ae[ae<span class="sc">&gt;</span><span class="dv">0</span>]),], <span class="dv">2</span>, quantile)</span>
<span id="cb19-3"><a href="#cb19-3" tabindex="-1"></a>difference <span class="ot">=</span> <span class="fu">apply</span>((effect<span class="sc">-</span>no_effect), <span class="dv">2</span>, mean)</span>
<span id="cb19-4"><a href="#cb19-4" tabindex="-1"></a>difference[difference <span class="sc">&gt;</span> <span class="fl">0.1</span>]</span></code></pre></div>
<p>There seems to be a difference in some variables like
<code>Education</code> and <code>Marital_Status</code>.</p>
<p>We can further analyze the individuals:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" tabindex="-1"></a>test_data[ae <span class="sc">&gt;=</span> <span class="fu">median</span>(ae[ae<span class="sc">&gt;</span><span class="dv">0</span>]), <span class="fu">names</span>(<span class="fu">which</span>(difference <span class="sc">&gt;</span> <span class="fl">0.1</span>)), with <span class="ot">=</span> <span class="cn">FALSE</span>]</span></code></pre></div>
</div>
<div id="predicting-using-only-the-first-n-iterations" class="section level3">
<h3>Predicting using only the first ‘n’ iterations</h3>
<p>Multi-calibration is an iterative procedure. The <code>t</code>
parameter can be used to predict using only the first <code>t</code>
iterations. This then predicts using only the first <code>t</code>
iterations of the multi-calibration procedure.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" tabindex="-1"></a>prs <span class="ot">=</span> mc<span class="sc">$</span><span class="fu">predict_probs</span>(test_data, <span class="at">t =</span> <span class="dv">3</span><span class="dt">L</span>)</span></code></pre></div>
</div>
</div>
<div id="example-2-mcboost-with-non-mlr3-models-glm" class="section level2">
<h2>Example 2: MCBoost with non-mlr3 models: GLM</h2>
<p><code>mcboost</code> does not require your model to be a
<code>mlr3</code> model. As an input, <code>mcboost</code> expects a
function <code>init_predictor</code> that takes as input
<code>data</code> and returns a prediction.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" tabindex="-1"></a>tsk <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">&quot;sonar&quot;</span>)</span>
<span id="cb22-2"><a href="#cb22-2" tabindex="-1"></a>data <span class="ot">=</span> tsk<span class="sc">$</span><span class="fu">data</span>()[, Class <span class="sc">:=</span> <span class="fu">as.integer</span>(Class) <span class="sc">-</span> <span class="dv">1</span><span class="dt">L</span>]</span>
<span id="cb22-3"><a href="#cb22-3" tabindex="-1"></a>mod <span class="ot">=</span> <span class="fu">glm</span>(<span class="at">data =</span> data, <span class="at">formula =</span> Class <span class="sc">~</span> .)</span></code></pre></div>
<p>The <code>init_predictor</code> could then use the <code>glm</code>
model:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" tabindex="-1"></a>init_predictor <span class="ot">=</span> <span class="cf">function</span>(data) {</span>
<span id="cb23-2"><a href="#cb23-2" tabindex="-1"></a>  <span class="fu">predict</span>(mod, data)</span>
<span id="cb23-3"><a href="#cb23-3" tabindex="-1"></a>}</span></code></pre></div>
<p>… and we can calibrate this predictor.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" tabindex="-1"></a>d <span class="ot">=</span> data[, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb24-2"><a href="#cb24-2" tabindex="-1"></a>l <span class="ot">=</span> data<span class="sc">$</span>Class</span>
<span id="cb24-3"><a href="#cb24-3" tabindex="-1"></a>mc <span class="ot">=</span> MCBoost<span class="sc">$</span><span class="fu">new</span>(<span class="at">init_predictor =</span> init_predictor)</span>
<span id="cb24-4"><a href="#cb24-4" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">multicalibrate</span>(d[<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>,], l[<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>])</span>
<span id="cb24-5"><a href="#cb24-5" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">predict_probs</span>(d[<span class="dv">201</span><span class="sc">:</span><span class="dv">208</span>,])</span></code></pre></div>
</div>
<div id="example-3-avoiding-overfitting-in-mcboost" class="section level2">
<h2>Example 3: Avoiding Overfitting in MCBoost</h2>
<p>Very often <code>MCBoost</code>’s calibration is very aggressive and
tends to overfit. This section tries to introduce a method to regularize
against this overfitting.</p>
<div id="cvlearner" class="section level3">
<h3>3.1 CVLearner</h3>
<p>In this section we use a <code>Cross-Validated</code> learner that
predicts on held-out data during the training phase. This idea is based
on Wolpert (1992)’s Stacked Generalization. Other, simpler methods
include choosing a smaller step size <code>eta</code> or reducing the
number of <code>iters</code>.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" tabindex="-1"></a>tsk <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">&quot;sonar&quot;</span>)</span></code></pre></div>
<p>As an <code>init_predictor</code> we again use a <code>ranger</code>
model from mlr3 and construct an init predictor using the convenience
function provided by <code>mcboost</code>.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">&quot;classif.ranger&quot;</span>, <span class="at">predict_type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb26-2"><a href="#cb26-2" tabindex="-1"></a>learner<span class="sc">$</span><span class="fu">train</span>(tsk)</span>
<span id="cb26-3"><a href="#cb26-3" tabindex="-1"></a>init_predictor <span class="ot">=</span> <span class="fu">mlr3_init_predictor</span>(learner)</span></code></pre></div>
<p>… and we can calibrate this predictor. This time, we use a
<code>CVTreeAuditorFitter</code> instead of a
<code>TreeAuditorFitter</code>. This allows us to avoid overfitting
similar to a technique coined <code>stacked generalization</code> first
described by Wolpert in 1992. Note, that this can sometimes take a
little longer since each learner is cross-validated using <code>3</code>
folds (default).</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" tabindex="-1"></a>d <span class="ot">=</span> data[, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb27-2"><a href="#cb27-2" tabindex="-1"></a>l <span class="ot">=</span> data<span class="sc">$</span>Class</span>
<span id="cb27-3"><a href="#cb27-3" tabindex="-1"></a>mc <span class="ot">=</span> MCBoost<span class="sc">$</span><span class="fu">new</span>(<span class="at">init_predictor =</span> init_predictor, <span class="at">auditor_fitter=</span>CVTreeAuditorFitter<span class="sc">$</span><span class="fu">new</span>(), <span class="at">max_iter =</span> <span class="dv">2</span><span class="dt">L</span>)</span>
<span id="cb27-4"><a href="#cb27-4" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">multicalibrate</span>(d[<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>,], l[<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>])</span>
<span id="cb27-5"><a href="#cb27-5" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">predict_probs</span>(d[<span class="dv">201</span><span class="sc">:</span><span class="dv">208</span>,])</span></code></pre></div>
</div>
<div id="data-splitting" class="section level3">
<h3>3.2 Data Splitting</h3>
<p>We can also use a fresh chunk of the validation data in each
iteration. <code>mcboost</code> implements two strategies,
<code>&quot;bootstrap&quot;</code> and <code>&quot;split&quot;</code>. While
<code>&quot;split&quot;</code> simply splits up the data, <code>&quot;bootstrap&quot;</code>
draws a new bootstrap sample of the data in each iteration.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" tabindex="-1"></a>tsk <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">&quot;sonar&quot;</span>)</span></code></pre></div>
<p>Again, we use a <code>ranger</code> mlr3 model as our initial
predictor:</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" tabindex="-1"></a>learner <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">&quot;classif.ranger&quot;</span>, <span class="at">predict_type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb29-2"><a href="#cb29-2" tabindex="-1"></a>learner<span class="sc">$</span><span class="fu">train</span>(tsk)</span>
<span id="cb29-3"><a href="#cb29-3" tabindex="-1"></a>init_predictor <span class="ot">=</span> <span class="fu">mlr3_init_predictor</span>(learner)</span></code></pre></div>
<p>and we can now calibrate:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" tabindex="-1"></a>d <span class="ot">=</span> data[, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb30-2"><a href="#cb30-2" tabindex="-1"></a>l <span class="ot">=</span> data<span class="sc">$</span>Class</span>
<span id="cb30-3"><a href="#cb30-3" tabindex="-1"></a>mc <span class="ot">=</span> MCBoost<span class="sc">$</span><span class="fu">new</span>(</span>
<span id="cb30-4"><a href="#cb30-4" tabindex="-1"></a>  <span class="at">init_predictor =</span> init_predictor,</span>
<span id="cb30-5"><a href="#cb30-5" tabindex="-1"></a>  <span class="at">auditor_fitter=</span> TreeAuditorFitter<span class="sc">$</span><span class="fu">new</span>(),</span>
<span id="cb30-6"><a href="#cb30-6" tabindex="-1"></a>  <span class="at">iter_sampling =</span> <span class="st">&quot;bootstrap&quot;</span></span>
<span id="cb30-7"><a href="#cb30-7" tabindex="-1"></a>)</span>
<span id="cb30-8"><a href="#cb30-8" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">multicalibrate</span>(d[<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>,], l[<span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>])</span>
<span id="cb30-9"><a href="#cb30-9" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">predict_probs</span>(d[<span class="dv">201</span><span class="sc">:</span><span class="dv">208</span>,])</span></code></pre></div>
</div>
</div>
<div id="example-4-adjusting-the-subpop-fitter" class="section level2">
<h2>Example 4: Adjusting the SubPop Fitter</h2>
<p>For this example, we use the <em>sonar</em> dataset once again:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" tabindex="-1"></a>tsk <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">&quot;sonar&quot;</span>)</span>
<span id="cb31-2"><a href="#cb31-2" tabindex="-1"></a>data <span class="ot">=</span> tsk<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> tsk<span class="sc">$</span>feature_names)</span>
<span id="cb31-3"><a href="#cb31-3" tabindex="-1"></a>labels <span class="ot">=</span> tsk<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> tsk<span class="sc">$</span>target_names)[[<span class="dv">1</span>]]</span></code></pre></div>
<div id="learnerauditorfitter" class="section level3">
<h3>4.1 LearnerAuditorFitter</h3>
<p>The Subpop-fitter can be easily adjusted by constructing it from a
<code>LearnerAuditorFitter</code>. This allows for using any
<strong>mlr3</strong> learner. See <a href="https://mlr3extralearners.mlr-org.com/articles/learners/list_learners.html">here</a>
for a list of available learners.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" tabindex="-1"></a>rf <span class="ot">=</span> LearnerAuditorFitter<span class="sc">$</span><span class="fu">new</span>(<span class="fu">lrn</span>(<span class="st">&quot;regr.rpart&quot;</span>, <span class="at">minsplit =</span> <span class="dv">10</span><span class="dt">L</span>))</span>
<span id="cb32-2"><a href="#cb32-2" tabindex="-1"></a>mc <span class="ot">=</span> MCBoost<span class="sc">$</span><span class="fu">new</span>(<span class="at">auditor_fitter =</span> rf)</span>
<span id="cb32-3"><a href="#cb32-3" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">multicalibrate</span>(data, labels)</span></code></pre></div>
<p>The <code>TreeAuditorFitter</code> and
<code>RidgeAuditorFitter</code> are two instantiations of this Fitter
with pre-defined learners. By providing their character strings the
fitter could be automatically constructed.</p>
</div>
<div id="subpopauditorfitter-subgroupauditorfitter" class="section level3">
<h3>4.2 SubpopAuditorFitter &amp; SubgroupAuditorFitter</h3>
<p>In some occasions, instead of using a <code>Learner</code>, we might
want to use a fixed set of subgroups. Those can either be defined from
the data itself or provided from the outside.</p>
<p><strong>Splitting via the dataset</strong></p>
<p>In order to split the data into groups according to a set of columns,
we use a <code>SubpopAuditorFitter</code> together with a list of
<code>subpops</code>. Those define the group splits to multi-calibrate
on. These splits can be either a <code>character</code> string,
referencing a binary variable in the data or a <code>function</code>
that, when evaluated on the data, returns a binary vector.</p>
<p>In order to showcase both options, we add a binary variable to our
<code>data</code>:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" tabindex="-1"></a>data[, Bin <span class="sc">:=</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>), <span class="fu">nrow</span>(data), <span class="at">replace =</span> <span class="cn">TRUE</span>)]</span></code></pre></div>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" tabindex="-1"></a>rf <span class="ot">=</span> SubpopAuditorFitter<span class="sc">$</span><span class="fu">new</span>(<span class="fu">list</span>(</span>
<span id="cb34-2"><a href="#cb34-2" tabindex="-1"></a>  <span class="st">&quot;Bin&quot;</span>,</span>
<span id="cb34-3"><a href="#cb34-3" tabindex="-1"></a>  <span class="cf">function</span>(data) {data[[<span class="st">&quot;V1&quot;</span>]] <span class="sc">&gt;</span> <span class="fl">0.2</span>},</span>
<span id="cb34-4"><a href="#cb34-4" tabindex="-1"></a>  <span class="cf">function</span>(data) {data[[<span class="st">&quot;V1&quot;</span>]] <span class="sc">&gt;</span> <span class="fl">0.2</span> <span class="sc">|</span> data[[<span class="st">&quot;V3&quot;</span>]] <span class="sc">&lt;</span> <span class="fl">0.29</span>}</span>
<span id="cb34-5"><a href="#cb34-5" tabindex="-1"></a>))</span></code></pre></div>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" tabindex="-1"></a>mc <span class="ot">=</span> MCBoost<span class="sc">$</span><span class="fu">new</span>(<span class="at">auditor_fitter =</span> rf)</span>
<span id="cb35-2"><a href="#cb35-2" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">multicalibrate</span>(data, labels)</span></code></pre></div>
<p>And we can again apply it to predict on new data:</p>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">predict_probs</span>(data)</span></code></pre></div>
<p><strong>Manually defined masks</strong></p>
<p>If we want to add the splitting from the outside, by supplying binary
masks for the rows of the data, we can provide manually defined masks.
Note, that the masks have to correspond with the number of rows in the
dataset.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" tabindex="-1"></a>rf <span class="ot">=</span> SubgroupAuditorFitter<span class="sc">$</span><span class="fu">new</span>(<span class="fu">list</span>(</span>
<span id="cb37-2"><a href="#cb37-2" tabindex="-1"></a>  <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">104</span>),</span>
<span id="cb37-3"><a href="#cb37-3" tabindex="-1"></a>  <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>), <span class="dv">52</span>)</span>
<span id="cb37-4"><a href="#cb37-4" tabindex="-1"></a>))</span></code></pre></div>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" tabindex="-1"></a>mc <span class="ot">=</span> MCBoost<span class="sc">$</span><span class="fu">new</span>(<span class="at">auditor_fitter =</span> rf)</span>
<span id="cb38-2"><a href="#cb38-2" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">multicalibrate</span>(data, labels)</span></code></pre></div>
<p>During prediction, we now have to supply a set of masks for the
prediction data.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" tabindex="-1"></a>predict_masks <span class="ot">=</span> <span class="fu">list</span>(</span>
<span id="cb39-2"><a href="#cb39-2" tabindex="-1"></a>  <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dv">52</span>),</span>
<span id="cb39-3"><a href="#cb39-3" tabindex="-1"></a>  <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>), <span class="dv">26</span>)</span>
<span id="cb39-4"><a href="#cb39-4" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">predict_probs</span>(data[<span class="dv">1</span><span class="sc">:</span><span class="dv">104</span>,], <span class="at">subgroup_masks =</span> predict_masks)</span></code></pre></div>
</div>
</div>
<div id="example-5-multi-calibrating-data-with-missing-values-using-a-pipeline" class="section level2">
<h2>Example 5: Multi-Calibrating data with missing values using a
pipeline</h2>
<p>When data has missing values or other non-standard columns, we often
have to pre-process data in order to be able to fit models. Those
preprocessing steps can be embedded into the <code>SubPopFitter</code>
by using a <strong>mlr3pipelines</strong> Pipeline. The following code
shows a brief example:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" tabindex="-1"></a>tsk <span class="ot">=</span> <span class="fu">tsk</span>(<span class="st">&quot;penguins&quot;</span>)</span>
<span id="cb41-2"><a href="#cb41-2" tabindex="-1"></a><span class="co"># first we convert to a binary task</span></span>
<span id="cb41-3"><a href="#cb41-3" tabindex="-1"></a>row_ids <span class="ot">=</span> tsk<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> <span class="fu">c</span>(<span class="st">&quot;species&quot;</span>, <span class="st">&quot;..row_id&quot;</span>))[species <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;Adelie&quot;</span>, <span class="st">&quot;Gentoo&quot;</span>)][[<span class="st">&quot;..row_id&quot;</span>]]</span>
<span id="cb41-4"><a href="#cb41-4" tabindex="-1"></a>tsk<span class="sc">$</span><span class="fu">filter</span>(row_ids)<span class="sc">$</span><span class="fu">droplevels</span>()</span>
<span id="cb41-5"><a href="#cb41-5" tabindex="-1"></a>tsk</span></code></pre></div>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;mlr3pipelines&quot;</span>)</span>
<span id="cb42-2"><a href="#cb42-2" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;mlr3learners&quot;</span>)</span>
<span id="cb42-3"><a href="#cb42-3" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" tabindex="-1"></a><span class="co"># Convert task to X,y</span></span>
<span id="cb42-5"><a href="#cb42-5" tabindex="-1"></a>X <span class="ot">=</span> tsk<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> tsk<span class="sc">$</span>feature_names)</span>
<span id="cb42-6"><a href="#cb42-6" tabindex="-1"></a>y <span class="ot">=</span> tsk<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> tsk<span class="sc">$</span>target_names)</span>
<span id="cb42-7"><a href="#cb42-7" tabindex="-1"></a></span>
<span id="cb42-8"><a href="#cb42-8" tabindex="-1"></a><span class="co"># Our inital model is a pipeline that imputes missings and encodes categoricals</span></span>
<span id="cb42-9"><a href="#cb42-9" tabindex="-1"></a>init_model <span class="ot">=</span> <span class="fu">as_learner</span>(<span class="fu">po</span>(<span class="st">&quot;encode&quot;</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">&quot;imputehist&quot;</span>) <span class="sc">%&gt;&gt;%</span></span>
<span id="cb42-10"><a href="#cb42-10" tabindex="-1"></a>  <span class="fu">lrn</span>(<span class="st">&quot;classif.glmnet&quot;</span>, <span class="at">predict_type =</span> <span class="st">&quot;prob&quot;</span>))</span>
<span id="cb42-11"><a href="#cb42-11" tabindex="-1"></a><span class="co"># And we fit it on a subset of the data in order to simulate a poorly performing model.</span></span>
<span id="cb42-12"><a href="#cb42-12" tabindex="-1"></a>init_model<span class="sc">$</span><span class="fu">train</span>(tsk<span class="sc">$</span><span class="fu">clone</span>()<span class="sc">$</span><span class="fu">filter</span>(row_ids[<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">9</span>, <span class="dv">160</span><span class="sc">:</span><span class="dv">170</span>)]))</span>
<span id="cb42-13"><a href="#cb42-13" tabindex="-1"></a>init_model<span class="sc">$</span><span class="fu">predict</span>(tsk)<span class="sc">$</span><span class="fu">score</span>()</span>
<span id="cb42-14"><a href="#cb42-14" tabindex="-1"></a></span>
<span id="cb42-15"><a href="#cb42-15" tabindex="-1"></a><span class="co"># We define a pipeline that imputes missings and encodes categoricals</span></span>
<span id="cb42-16"><a href="#cb42-16" tabindex="-1"></a>auditor <span class="ot">=</span> <span class="fu">as_learner</span>(<span class="fu">po</span>(<span class="st">&quot;encode&quot;</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">po</span>(<span class="st">&quot;imputehist&quot;</span>) <span class="sc">%&gt;&gt;%</span> <span class="fu">lrn</span>(<span class="st">&quot;regr.rpart&quot;</span>))</span>
<span id="cb42-17"><a href="#cb42-17" tabindex="-1"></a></span>
<span id="cb42-18"><a href="#cb42-18" tabindex="-1"></a>mc <span class="ot">=</span> MCBoost<span class="sc">$</span><span class="fu">new</span>(<span class="at">auditor_fitter =</span> auditor, <span class="at">init_predictor =</span> init_model)</span>
<span id="cb42-19"><a href="#cb42-19" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">multicalibrate</span>(X, y)</span></code></pre></div>
<p>and we can observe where it improved:</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" tabindex="-1"></a>mc</span></code></pre></div>
</div>
<div id="example-6-multi-calibration-regression" class="section level2">
<h2>Example 6: Multi-Calibration Regression</h2>
<p>We abuse the <code>Communities &amp; Crime</code> dataset in order to
showcase how <code>mcboost</code> can be used in a regression
setting.</p>
<p>First we download the data and create an <code>mlr3</code> regression
task:</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb44-2"><a href="#cb44-2" tabindex="-1"></a><span class="fu">library</span>(mlr3oml)</span>
<span id="cb44-3"><a href="#cb44-3" tabindex="-1"></a>oml <span class="ot">=</span> OMLData<span class="sc">$</span><span class="fu">new</span>(<span class="dv">42730</span>)</span>
<span id="cb44-4"><a href="#cb44-4" tabindex="-1"></a>data <span class="ot">=</span> oml<span class="sc">$</span>data</span>
<span id="cb44-5"><a href="#cb44-5" tabindex="-1"></a></span>
<span id="cb44-6"><a href="#cb44-6" tabindex="-1"></a>tsk <span class="ot">=</span> TaskRegr<span class="sc">$</span><span class="fu">new</span>(<span class="st">&quot;communities_crime&quot;</span>, data, <span class="at">target =</span> <span class="st">&quot;ViolentCrimesPerPop&quot;</span>)</span></code></pre></div>
<p>Currently, <strong>mcboost</strong> only allows to work with targets
between 0 and 1. Luckily, our target variable’s values are already in
that range, but if they were not, we could simply scale them to [0;1]
before our analysis.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" tabindex="-1"></a><span class="fu">summary</span>(data<span class="sc">$</span>ViolentCrimesPerPop)</span></code></pre></div>
<p>We again split our task into <strong>train</strong> and
<strong>test</strong>. We do this in <code>mlr3</code> by creating a 2/3
- 1/3 split using <code>mlr3::partition()</code> and assigning the train
ids to the row role <code>&quot;use&quot;</code>.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" tabindex="-1"></a>split <span class="ot">=</span> <span class="fu">partition</span>(tsk)</span>
<span id="cb46-2"><a href="#cb46-2" tabindex="-1"></a>tsk<span class="sc">$</span><span class="fu">set_row_roles</span>(split<span class="sc">$</span>train, <span class="st">&quot;use&quot;</span>)</span></code></pre></div>
<div id="preprocessing-1" class="section level3">
<h3>6.1 Preprocessing</h3>
<p>Then we do basic preprocessing, since we do not have any categorical
variables, we only impute NA’s using a histogram approach.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" tabindex="-1"></a><span class="fu">library</span>(mlr3pipelines)</span>
<span id="cb47-2"><a href="#cb47-2" tabindex="-1"></a>pipe <span class="ot">=</span>  <span class="fu">po</span>(<span class="st">&quot;imputehist&quot;</span>)</span>
<span id="cb47-3"><a href="#cb47-3" tabindex="-1"></a>prep_task <span class="ot">=</span> pipe<span class="sc">$</span><span class="fu">train</span>(<span class="fu">list</span>(tsk))[[<span class="dv">1</span>]]</span>
<span id="cb47-4"><a href="#cb47-4" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" tabindex="-1"></a>prep_task<span class="sc">$</span><span class="fu">set_col_roles</span>(<span class="fu">c</span>(<span class="st">&quot;racepctblack&quot;</span>, <span class="st">&quot;racePctWhite&quot;</span>, <span class="st">&quot;racePctAsian&quot;</span>, <span class="st">&quot;racePctHisp&quot;</span>, <span class="st">&quot;community&quot;</span>), <span class="at">remove_from =</span> <span class="st">&quot;feature&quot;</span>)</span></code></pre></div>
<p>Now we fit our first <code>Learner</code>: A
<code>random forest</code>.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" tabindex="-1"></a><span class="fu">library</span>(mlr3learners)</span>
<span id="cb48-2"><a href="#cb48-2" tabindex="-1"></a>l <span class="ot">=</span> <span class="fu">lrn</span>(<span class="st">&quot;regr.ranger&quot;</span>, <span class="at">num.trees =</span> <span class="dv">10</span><span class="dt">L</span>)</span>
<span id="cb48-3"><a href="#cb48-3" tabindex="-1"></a>l<span class="sc">$</span><span class="fu">train</span>(prep_task)</span></code></pre></div>
</div>
<div id="mcboost-1" class="section level3">
<h3>6.2 MCBoost</h3>
<p>A simple way to use the predictions from any <code>Model</code> in
<strong>mcboost</strong> is to wrap the predict function and provide it
as an initial predictor. This can be done from any model / any library.
Note, that we have to make sure, that our <code>init_predictor</code>
returns a numeric vector of predictions.</p>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" tabindex="-1"></a>init_predictor <span class="ot">=</span> <span class="cf">function</span>(data) {</span>
<span id="cb49-2"><a href="#cb49-2" tabindex="-1"></a>  l<span class="sc">$</span><span class="fu">predict_newdata</span>(data)<span class="sc">$</span>response</span>
<span id="cb49-3"><a href="#cb49-3" tabindex="-1"></a>}</span></code></pre></div>
<p>As <strong>mcboost</strong> requires the data to be provided in
<code>X, y</code> format (a <code>data.table</code> or
<code>data.frame</code> of features and a vector of labels), we create
those two objects.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" tabindex="-1"></a>data <span class="ot">=</span> prep_task<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> prep_task<span class="sc">$</span>feature_names)</span>
<span id="cb50-2"><a href="#cb50-2" tabindex="-1"></a>labels <span class="ot">=</span> prep_task<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> prep_task<span class="sc">$</span>target_names)[[<span class="dv">1</span>]]</span></code></pre></div>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" tabindex="-1"></a>mc <span class="ot">=</span> MCBoost<span class="sc">$</span><span class="fu">new</span>(<span class="at">auditor_fitter =</span> <span class="st">&quot;RidgeAuditorFitter&quot;</span>, <span class="at">init_predictor =</span> init_predictor, <span class="at">eta =</span> <span class="fl">0.1</span>)</span>
<span id="cb51-2"><a href="#cb51-2" tabindex="-1"></a>mc<span class="sc">$</span><span class="fu">multicalibrate</span>(data, labels)</span></code></pre></div>
</div>
<div id="evaluation-on-test-data-1" class="section level3">
<h3>6.3 Evaluation on Test Data</h3>
<p>We first create the test task by assigning the test ids to the row
role <code>&quot;use&quot;</code>, and then use our preprocessing
<code>pipe&#39;s</code> predict function to also impute missing values for
the validation data. Then we again extract features <code>X</code> and
target <code>y</code>.</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" tabindex="-1"></a>test_task <span class="ot">=</span> tsk<span class="sc">$</span><span class="fu">clone</span>()</span>
<span id="cb52-2"><a href="#cb52-2" tabindex="-1"></a>test_task<span class="sc">$</span>row_roles<span class="sc">$</span>use <span class="ot">=</span> split<span class="sc">$</span>test</span>
<span id="cb52-3"><a href="#cb52-3" tabindex="-1"></a>test_task <span class="ot">=</span> pipe<span class="sc">$</span><span class="fu">predict</span>(<span class="fu">list</span>(test_task))[[<span class="dv">1</span>]]</span>
<span id="cb52-4"><a href="#cb52-4" tabindex="-1"></a>test_data <span class="ot">=</span> test_task<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> tsk<span class="sc">$</span>feature_names)</span>
<span id="cb52-5"><a href="#cb52-5" tabindex="-1"></a>test_labels <span class="ot">=</span> test_task<span class="sc">$</span><span class="fu">data</span>(<span class="at">cols =</span> tsk<span class="sc">$</span>target_names)[[<span class="dv">1</span>]]</span></code></pre></div>
<p>and <strong>predict</strong>.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" tabindex="-1"></a>prs <span class="ot">=</span> mc<span class="sc">$</span><span class="fu">predict_probs</span>(test_data)</span></code></pre></div>
<p>Now we can compute the MSE of the multi-calibrated model</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" tabindex="-1"></a><span class="fu">mean</span>((prs <span class="sc">-</span> test_labels)<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<p>and compare to the non-calibrated version:</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" tabindex="-1"></a><span class="fu">mean</span>((<span class="fu">init_predictor</span>(test_data) <span class="sc">-</span> test_labels)<span class="sc">^</span><span class="dv">2</span>)</span></code></pre></div>
<p>But looking at sub-populations we can see that the predictions got
more calibrated. Since we cannot show all subpopulations we only show
the MSE for the feature <code>racepctblack</code>.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" tabindex="-1"></a>test_data<span class="sc">$</span>se_mcboost <span class="ot">=</span> (prs <span class="sc">-</span> test_labels)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb56-2"><a href="#cb56-2" tabindex="-1"></a>test_data<span class="sc">$</span>se_init <span class="ot">=</span> (<span class="fu">init_predictor</span>(test_data) <span class="sc">-</span> test_labels)<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb56-3"><a href="#cb56-3" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" tabindex="-1"></a>test_data[, .(<span class="at">mcboost =</span> <span class="fu">mean</span>(se_mcboost), <span class="at">initial =</span> <span class="fu">mean</span>(se_init), .N), by <span class="ot">=</span> .(racepctblack <span class="sc">&gt;</span> <span class="fl">0.5</span>)]</span></code></pre></div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
